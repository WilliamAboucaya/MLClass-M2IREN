{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "174e65e8",
   "metadata": {},
   "source": [
    "# Logistic regression for a multi-class problem\n",
    "\n",
    "In this notebook, we are going to perform a logistic regression (cf. previous session slides and notebooks) on a classification problem where our classes are not just `positive` and `negative` (`pass` and `fail` in the previous notebook), but a larger range of possibilities. We are going to create a classifier identifying the dominant species of tree in a 30Ã—30 meters patch of forest, among 7 total possible tree covers. To do so, we will rely on a much larger number of possible features than during previous classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fba9fc7",
   "metadata": {},
   "source": [
    "## Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= fetch_covtype(data_home=os.getcwd() + \"/cache/\")\n",
    "df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "df[\"Cover_Type\"] = dataset.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab8b57",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858311d9",
   "metadata": {},
   "source": [
    "### Base statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class distribution:\\n\", df['Cover_Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(14, 6))\n",
    "for col, ax in zip(['Elevation','Slope','Aspect'], axes):\n",
    "    ax.hist(df[col], bins=40)\n",
    "    ax.set_title(f\"Distribution of {col}\")\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d676a2",
   "metadata": {},
   "source": [
    "### Correlation matrix between continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5258105",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = df.columns[:10].tolist()\n",
    "corr_matrix = df[continuous_features].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5, vmin=-1, vmax=1, ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode='anchor')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4052adc",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Here, we are going to create three additional features for our dataset: one computing the total hillshade of the patch, another one computing the Euclidian distance to the hydrology point, and a last one computing the interaction effect of distance to roadways and fire points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hillshade_Total'] = df[['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']].sum(axis='columns')\n",
    "\n",
    "df['Euclid_Distance_To_Hydrology'] = np.sqrt(\n",
    "    df['Horizontal_Distance_To_Hydrology']**2 + df['Vertical_Distance_To_Hydrology']**2\n",
    ")\n",
    "\n",
    "df['Road_Fire_Interaction'] = df['Horizontal_Distance_To_Roadways'] * df['Horizontal_Distance_To_Fire_Points']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a522cee",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Now that our dataset is ready, we are going to train our multi-class logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdfc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Cover_Type', axis=1)\n",
    "y = df['Cover_Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12647555",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(n_jobs=-1, max_iter=1000, penalty=\"l2\", random_state=1234))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(model[\"logreg\"].coef_, columns=X.columns, index=[f\"Class {c}\" for c in model[\"logreg\"].classes_])\n",
    "\n",
    "# Display top 10 predictors per class\n",
    "for cls in coef_df.index:\n",
    "    print(f\"Top predictors for {cls}:\")\n",
    "    print(coef_df.loc[cls].abs().sort_values(ascending=False).head(3))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7510f64",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b61c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00872e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    cmap=plt.cm.Blues\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc50d1e",
   "metadata": {},
   "source": [
    "As you can see, our model performs really well for classes with a lot ef examples (1 and 2) but has trouble generalizing to the less common classes. The model design itself can also be questioned and a good strategy if we wanted to improve performances would be to try other types of models (e.g., Random Forest, Gradient Boosting) and choose the one giving the best performances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
