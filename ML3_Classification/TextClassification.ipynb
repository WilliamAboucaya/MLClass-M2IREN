{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fbaaa86",
   "metadata": {},
   "source": [
    "# Logistic regression for a multi-class problem\n",
    "\n",
    "In this notebook, we are going to work on a classification problem using text as the initial input. To do so, we are going to train a language model which will learn to recognize the topic of a text based on its semantic representation. The classifier will be based on the DistillBERT model and will be trained on a small subsegment of the dataset to make training faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5bee3",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde668a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['HF_HOME'] = os.getcwd() + \"/cache/\"\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from evaluate import load\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers.utils import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4bcf87",
   "metadata": {},
   "source": [
    "## Identifying the best device to run the model\n",
    "\n",
    "Since we are going to perform a computing-intensive task, we must identify the most efficient device available to perform it. We do so using PyTorch, which is the back-end that we will use in this lab. We prioritize NVIDIA GPUs with CUDA installed, then Apple Silicon GPUs, and finally CPUs if none of the above is found.\n",
    "\n",
    "If you need help installing the relevant version of PyTorch: https://pytorch.org/get-started/locally/\n",
    "\n",
    "If you have a NVIDIA GPU but you don't know whether you have CUDA installed or not, type the following command:\n",
    "\n",
    "```bash\n",
    "nvcc --version\n",
    "```\n",
    "\n",
    "If you have it installed, you should see the CUDA version installed on your computer. Otherwise, you should install a PyTorch-compatible version (as listed [here](https://pytorch.org/get-started/locally/), row \"Stable CUDA\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa993ce",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be128664",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_dst = load_dataset(\"SetFit/20_newsgroups\")\n",
    "df: pd.DataFrame = pd.concat([newsgroups_dst[\"train\"].to_pandas(), newsgroups_dst[\"test\"].to_pandas()])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c332ea4b",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5491ab",
   "metadata": {},
   "source": [
    "Let's check if we have some empty texts and if so, we get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eacb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_empty_texts = (df.text == \"\").sum()\n",
    "\n",
    "print(f\"There are {num_empty_texts} empty rows in the dataset.\")\n",
    "\n",
    "df = df.loc[df.text != \"\"]\n",
    "print(\"Now, we only keep non-empty rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label_text.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(df.index)\n",
    "print(f\"The dataset is {num_rows} rows long.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5617a621",
   "metadata": {},
   "source": [
    "The data is too large to train it during this class, so we are going to produce a subsample. First, we will narrow down our scope by taking only the documents whose topic label starts with `sci`, i.e. `sci.crypt`, `sci.med`, `sci.space` and `sci.electronics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.loc[df.label_text.str.startswith(\"sci\")]\n",
    "normalized_labels = {label: i for i, label in enumerate(df_filtered.label_text.unique())}\n",
    "df_filtered.loc[:, \"label\"] = df_filtered.label_text.map(normalized_labels)\n",
    "print(f\"The dataset is {len(df_filtered.index)} rows long.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb8157",
   "metadata": {},
   "source": [
    "This is already a good improvement, but we will further reduce the number of rows by randomly sampling the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c80e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_filtered.groupby('label_text', group_keys=True).sample(n=400, random_state=1234)\n",
    "print(f\"The dataset is {len(df_sample.index)} rows long.\")\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95ce23",
   "metadata": {},
   "source": [
    "We now have a 1600 rows dataset with only 4 different topics perfectly balanced between the different labels. Now let's split it between train, valid and test dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_temp = train_test_split(\n",
    "    df_sample, \n",
    "    test_size=0.3,       # 30% goes to valid+test\n",
    "    stratify=df_sample['label_text'],\n",
    "    random_state=1234\n",
    ")\n",
    "\n",
    "df_valid, df_test = train_test_split(\n",
    "    df_temp,\n",
    "    test_size=0.5,       # 50% of the 30% -> 15% test, 15% valid\n",
    "    stratify=df_temp['label_text'],\n",
    "    random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d51ab",
   "metadata": {},
   "source": [
    "Now we re-convert our dataframes as Datasets as they are optimized to be used with our training framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6db2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = DatasetDict({\"train\": Dataset.from_pandas(df_train, preserve_index=False), \"validation\": Dataset.from_pandas(df_valid, preserve_index=False), \"test\": Dataset.from_pandas(df_test, preserve_index=False)})\n",
    "dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce359e",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Now, we will setup a model trainer for a DistillBERT model, which willfine-tune it on our new dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847dfca8",
   "metadata": {},
   "source": [
    "### Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_size = 8\n",
    "num_epochs = 5\n",
    "lr = 2e-5\n",
    "weight_decay = 0.01\n",
    "num_labels = len(normalized_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce15dc",
   "metadata": {},
   "source": [
    "### Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = dst.map(lambda example: tokenizer(example[\"text\"], max_length=512, truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \"f1\"\n",
    "metric = load(metric_name)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        \"f1_micro\": metric.compute(predictions=predictions, references=labels, average=\"micro\")[\"f1\"],\n",
    "        \"f1_macro\": metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62dcc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"./cache/newsgroups_classifier\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=training_batch_size,\n",
    "    per_device_eval_batch_size=training_batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=weight_decay,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    save_safetensors=True,\n",
    "    save_total_limit=3,\n",
    "    seed=1234\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84216af1",
   "metadata": {},
   "source": [
    "Now we are good to fine-tune our model on the dataset we created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c9c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_info()\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe109efe",
   "metadata": {},
   "source": [
    "## Assessing the model\n",
    "\n",
    "Now we can assess the performances of our finetuned model using the methods we have already seen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96258dbc",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74657ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(encoded_dataset[\"test\"])\n",
    "y_pred = predictions.predictions.argmax(-1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "label_list = list(sorted(normalized_labels.keys(), key=normalized_labels.get))\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98873d",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4fad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    display_labels=label_list,\n",
    "    cmap=\"Blues\",\n",
    "    xticks_rotation=\"vertical\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
